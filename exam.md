PART 1: Logistic Regression
‚ùì Q1: What is Logistic Regression used for?
Answer:
Logistic Regression is used for classification problems.
It predicts the probability that an observation belongs to a particular class (usually binary: 0 or 1).
‚ùì Q2: What is the sigmoid function?
Answer:
The sigmoid function transforms any real value into a number between 0 and 1.
œÉ
(
z
)
=
1
1
+
e
‚àí
z
œÉ(z)= 
1+e 
‚àíz
 
1
‚Äã	
 
It converts the linear equation output into a probability.
‚ùì Q3: What is the difference between Linear and Logistic Regression?
Answer:
Linear Regression	Logistic Regression
Predicts continuous values	Predicts probabilities
Output can be any real number	Output between 0 and 1
Uses MSE loss	Uses Log Loss
üîµ PART 2: Loss Function
‚ùì Q4: Why can't we use MSE in Logistic Regression?
Answer:
Because Logistic Regression uses a sigmoid function, which is non-linear.
Using MSE would result in a non-convex optimization problem.
Therefore, we use Log Loss (Cross-Entropy Loss).
‚ùì Q5: Write the formula for Log Loss.
Answer:
L
o
s
s
=
‚àí
[
y
log
‚Å°
(
p
)
+
(
1
‚àí
y
)
log
‚Å°
(
1
‚àí
p
)
]
Loss=‚àí[ylog(p)+(1‚àíy)log(1‚àíp)]
Where:
y = actual label (0 or 1)
p = predicted probability
üîµ PART 3: Classification Model Evaluation
‚ùì Q6: Define TP, TN, FP, FN.
Answer:
TP: True Positive (correct positive prediction)
TN: True Negative (correct negative prediction)
FP: False Positive (incorrect positive prediction)
FN: False Negative (incorrect negative prediction)
‚ùì Q7: Write formulas for Accuracy, Precision, and Recall.
Answer:
Accuracy:
A
c
c
u
r
a
c
y
=
T
P
+
T
N
T
P
+
T
N
+
F
P
+
F
N
Accuracy= 
TP+TN+FP+FN
TP+TN
‚Äã	
 
Precision:
P
r
e
c
i
s
i
o
n
=
T
P
T
P
+
F
P
Precision= 
TP+FP
TP
‚Äã	
 
Recall:
R
e
c
a
l
l
=
T
P
T
P
+
F
N
Recall= 
TP+FN
TP
‚Äã	
 
‚ùì Q8: When is Precision more important than Recall?
Answer:
Precision is more important when False Positives are costly.
Example:
Spam detection ‚Äî we don‚Äôt want to mark important emails as spam.
‚ùì Q9: When is Recall more important than Precision?
Answer:
Recall is more important when False Negatives are costly.
Example:
Disease detection ‚Äî we don‚Äôt want to miss a sick patient.
‚ùì Q10: What is an ROC curve?
Answer:
ROC curve is a graph that shows the tradeoff between:
True Positive Rate (Sensitivity)
False Positive Rate
The closer the curve is to the top-left corner, the better the model.
‚ùì Q11: What does AUC represent?
Answer:
AUC (Area Under Curve) measures the overall performance of the model.
AUC = 1 ‚Üí Perfect model
AUC = 0.5 ‚Üí Random guessing
AUC < 0.5 ‚Üí Worse than random
üîµ PART 4: Train/Test Split & K-Fold
‚ùì Q12: Why do we split data into training and testing sets?
Answer:
To evaluate how the model performs on unseen data and prevent overfitting.
‚ùì Q13: What is Overfitting?
Answer:
Overfitting occurs when the model performs very well on training data but poorly on new data.
‚ùì Q14: Explain K-Fold Cross Validation.
Answer:
In K-Fold Cross Validation:
The dataset is divided into K equal parts.
Each part is used once as validation data.
The remaining K-1 parts are used for training.
The results are averaged.
This provides a more reliable performance estimate.
üîµ PART 5: Data Pre-processing
‚ùì Q15: Why is feature scaling important?
Answer:
Feature scaling ensures that all features contribute equally to the model and prevents features with large values from dominating.
‚ùì Q16: What is the difference between Normalization and Standardization?
Answer:
Normalization:
x
‚Ä≤
=
x
‚àí
m
i
n
m
a
x
‚àí
m
i
n
x 
‚Ä≤
 = 
max‚àímin
x‚àímin
‚Äã	
 
Scales data between 0 and 1.
Standardization:
z
=
x
‚àí
Œº
œÉ
z= 
œÉ
x‚àíŒº
‚Äã	
 
Centers data around mean 0 with standard deviation 1.
‚ùì Q17: How do we handle missing values?
Answer:
Remove rows with missing values
Replace with mean/median
Use predictive models
üîµ PART 6: Data Visualization
‚ùì Q18: Why is data visualization important?
Answer:
It helps to:
Understand data distribution
Detect outliers
Identify relationships between variables
‚ùì Q19: Name three common plots used in data visualization.
Answer:
Histogram
Scatter Plot
Boxplot
üî• BONUS: Calculation Question (Professor Style)
‚ùì Q20:
Suppose:
TP = 40
TN = 50
FP = 10
FN = 20
Calculate:
Accuracy
Precision
Recall
‚úÖ Answer:
Total = 40 + 50 + 10 + 20 = 120
Accuracy:
(
40
+
50
)
/
120
=
90
/
120
=
0.75
=
75
(40+50)/120=90/120=0.75=75
Precision:
40
/
(
40
+
10
)
=
40
/
50
=
0.80
=
80
40/(40+10)=40/50=0.80=80
Recall:
40
/
(
40
+
20
)
=
40
/
60
=
0.67
=
67
40/(40+20)=40/60=0.67=67


Question 1 ‚Äî Train/Test Split
‚ùì Task:
Load a dataset and split it into training and testing sets.
üß† Skills tested:
train_test_split
preparing ML data
‚úÖ Python Solution:
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancer

# Load dataset
data = load_breast_cancer()
X = data.data
y = data.target

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(X_train.shape)
print(X_test.shape)
‚úÖ Question 2 ‚Äî Train Logistic Regression Model
‚ùì Task:
Train a Logistic Regression model using training data.
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=10000)
model.fit(X_train, y_train)
‚úÖ Question 3 ‚Äî Make Predictions
‚ùì Task:
Predict class labels using test data.
y_pred = model.predict(X_test)
‚úÖ Question 4 ‚Äî Confusion Matrix
‚ùì Task:
Display confusion matrix.
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)
print(cm)
Output example:
[[TN FP]
 [FN TP]]
‚úÖ Question 5 ‚Äî Accuracy, Precision, Recall
from sklearn.metrics import accuracy_score, precision_score, recall_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
‚úÖ Question 6 ‚Äî ROC Curve
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

y_prob = model.predict_proba(X_test)[:,1]

fpr, tpr, thresholds = roc_curve(y_test, y_prob)

plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.show()
‚úÖ Question 7 ‚Äî K-Fold Cross Validation
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=10)

print(scores)
print("Average Accuracy:", scores.mean())
‚úÖ Question 8 ‚Äî Data Scaling (Pre-processing)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
‚úÖ Question 9 ‚Äî Visualization (Data Understanding)
import matplotlib.pyplot as plt

plt.hist(X[:,0])
plt.title("Feature Distribution")
plt.show()
üéØ PROFESSOR TIPS (VERY IMPORTANT)
Many students lose marks because:
‚ùå They scale BEFORE splitting data.
Correct order:
Split data
‚Üí Fit scaler on TRAIN only
‚Üí Transform test data



‚úÖ Q1: What is Logistic Regression used for?
Expected answer:
Used for binary classification.
Outputs probability between 0 and 1 using sigmoid function.
‚úÖ Q2: Write the sigmoid function formula.
œÉ
(
z
)
=
1
1
+
e
‚àí
z
œÉ(z)= 
1+e 
‚àíz
 
1
‚Äã	
 
They may ask:
Why is sigmoid used?
Answer:
To convert linear output into probability.
‚úÖ Q3: What is overfitting?
Expected answer:
Model performs very well on training data but poorly on new unseen data.
‚úÖ Q4: Why do we split data into train and test sets?
Answer:
To evaluate performance on unseen data.
To prevent overfitting.
‚úÖ Q5: Explain K-Fold Cross Validation.
Answer:
Dataset is divided into K parts.
Each part is used once for testing.
The remaining K-1 parts are used for training.
Results are averaged.
üîµ PART 2 ‚Äî CONFUSION MATRIX QUESTIONS (VERY LIKELY)
You will almost 100% get one like this.
‚úÖ Q6: Define TP, TN, FP, FN.
Be ready to explain clearly.
‚úÖ Q7: Given this confusion matrix:
TP = 30
TN = 50
FP = 10
FN = 10
Calculate:
Accuracy
Precision
Recall
You must know formulas.
Expected formulas:
Accuracy:
T
P
+
T
N
T
o
t
a
l
Total
TP+TN
‚Äã	
 
Precision:
T
P
T
P
+
F
P
TP+FP
TP
‚Äã	
 
Recall:
T
P
T
P
+
F
N
TP+FN
TP
‚Äã	
 
üîµ PART 3 ‚Äî ROC & AUC QUESTIONS (VERY COMMON)
‚úÖ Q8: What does ROC curve represent?
Answer:
Trade-off between True Positive Rate and False Positive Rate.
‚úÖ Q9: What does AUC = 0.5 mean?
Answer:
Model performs like random guessing.
‚úÖ Q10: If ROC curve is close to diagonal line, what does it mean?
Answer:
Poor model.
üîµ PART 4 ‚Äî DATA PREPROCESSING QUESTIONS
These are very common.
‚úÖ Q11: Why is feature scaling important?
Answer:
To prevent features with large values from dominating.
Important for models like Logistic Regression.
‚úÖ Q12: Difference between normalization and standardization?
Normalization:
(
x
‚àí
m
i
n
)
/
(
m
a
x
‚àí
m
i
n
)
(x‚àímin)/(max‚àímin)
Standardization:
(
x
‚àí
Œº
)
/
œÉ
(x‚àíŒº)/œÉ
‚úÖ Q13: Should we scale before or after train-test split?
Correct answer:
After splitting.
Fit scaler only on training data.
This is a very tricky question professors love.
üîµ PART 5 ‚Äî SHORT ANSWER CONCEPT QUESTIONS
‚úÖ Q14: When is precision more important than recall?
Answer:
When false positives are costly (e.g., spam filter).
‚úÖ Q15: When is recall more important than precision?
Answer:
When false negatives are costly (e.g., cancer detection).
‚úÖ Q16: Why don‚Äôt we use MSE for Logistic Regression?
Answer:
Because sigmoid is non-linear.
MSE causes non-convex optimization.
üîµ PART 6 ‚Äî CODING QUESTIONS (If practical exam)
You may be asked to:
Use train_test_split
Train logistic regression
Print confusion matrix
Calculate accuracy
Plot ROC curve
Use cross_val_score
üî• MOST IMPORTANT TOPICS (HIGH PRIORITY)
If you are short on time, focus on:
1Ô∏è‚É£ Confusion Matrix
2Ô∏è‚É£ Precision vs Recall
3Ô∏è‚É£ ROC & AUC
4Ô∏è‚É£ Train/Test vs K-Fold
5Ô∏è‚É£ Feature Scaling
6Ô∏è‚É£ Overfitting
These are almost guaranteed.
‚ö†Ô∏è PROFESSOR TRICK QUESTIONS
Be careful with:
üëâ ‚ÄúHigh accuracy always means good model.‚Äù
Answer: False.
üëâ ‚ÄúROC below diagonal means good model.‚Äù
Answer: False.
üëâ ‚ÄúK-Fold eliminates overfitting.‚Äù
Answer: False (it reduces bias, but does not eliminate).
üëâ ‚ÄúScaling should be done before splitting.‚Äù
Answer: False.
üéØ If I Predict Your Exam
Most likely structure:
Section A ‚Äî Definitions
Section B ‚Äî Confusion Matrix calculation
Section C ‚Äî Explain ROC
Section D ‚Äî Train/Test or K-Fold
Section E ‚Äî Preprocessing